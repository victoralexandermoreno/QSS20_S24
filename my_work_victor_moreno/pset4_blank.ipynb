{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 4: APIs, SQL, and supervised machine learning\n",
    "\n",
    "**Total points (without extra credit)**: 48 \n",
    "\n",
    "\n",
    "## Resources from class\n",
    "\n",
    "### APIs\n",
    "- [Lecture slides](https://docs.google.com/presentation/d/1eblPOhpOL1HDFk3XOh3KvcrFceJ4pwZNUU_fvU8i7uo/edit#slide=id.p)\n",
    "- [Activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/06_apis_solutions.ipynb)\n",
    "\n",
    "\n",
    "### Supervised ML\n",
    "- [Lecture slides 1](https://docs.google.com/presentation/d/1V6X9aYkYLvyh3Ea0ZSn3qkttqKz7OOPkfvbqYybMi5Q/edit#slide=id.p)\n",
    "- [Lecture slides 2](https://docs.google.com/presentation/d/13xJTI_GZ2HZYI9OSmezwLUXXFxIrjwHXKz50QUjBF0w/edit)\n",
    "- [Intro activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/08_ML_intro_activity_solutions.ipynb)\n",
    "- [Part II activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/08_ML_optimization_activity_solutions.ipynb)\n",
    "- [DataCamp course](https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn)\n",
    "\n",
    "### SQL\n",
    "- [Lecture slides](https://docs.google.com/presentation/d/1HHgrkFtuhGIaPNMd1EOiM-8VtgnF0cwjMcmah8oWmWA/edit?usp=sharing)\n",
    "- [Example code](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/09_SQL_examplecode.ipynb)\n",
    "- [Activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/09_SQL_activity_solutions.ipynb)\n",
    "- [DataCamp course](https://app.datacamp.com/learn/courses/introduction-to-sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep work: change SQL dataset\n",
    "\n",
    "- Place it in [the same credentials yaml file on GitHub that contains the SQL database access information](https://github.com/herbertfreeze/QSS_public/blob/main/activities/09_db_cred.yaml) (password, host, etc.) \n",
    "    - Name the combined credentials file something appropriate (feel free to get creative)\n",
    "    - Change the database name from `sentencing` to `math_gencompare`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note you need to install some of the packages imported below (see the comments).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## note: you may need to install these using !pip install\n",
    "#!pip install census\n",
    "#!pip install us\n",
    "import census\n",
    "from census import Census\n",
    "import us\n",
    "from us import states\n",
    "import mysql.connector\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "def load_creds(path: str):\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            creds = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return(creds)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a wrapper function to pull data from the NAEP API (12 points)\n",
    "\n",
    "In the class activity on APIs (see link above), we practiced pulling from the API for the National Assessment of Educational Progress (NAEP), \"America's report card\" of test scores. We pulled a small amount of data at the national level (writing scores by gender) using a query where the parameters were hardcoded.\n",
    "    \n",
    "In this problem, we'll practice pulling a larger set of data and writing a wrapper function.\n",
    "    \n",
    "As a reminder, the documentation is here: https://www.nationsreportcard.gov/api_documentation.aspx\n",
    "\n",
    "The base link is: https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Write a query to pull 8th-grade mathematics scores in 2015 from the state of California (CA) by gender (1 point)\n",
    "\n",
    "- Subject: mathematics \n",
    "- Subscale: MRPCM composite scale \n",
    "- Grade: 8\n",
    "- Year: 2015\n",
    "- grouping variable: GENDER \n",
    "- Jurisdiction: CA \n",
    "- stattype = MN (for mean)\n",
    "\n",
    "Print the output in dataframe format and briefly interpret; what do scores look like between the genders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Write a query to pull 8th-grade mathematics scores in 2013, 2015, 2017, and 2019 from California by gender (1 point)\n",
    "\n",
    "Same as 1.1 but pull the years 2013, 2015, 2017, and 2019 (search documentation for how to combine) in one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create a line plot to show variation in the scores across years (2 points)\n",
    "\n",
    "Using the results from 1.2, create a plot where the x axis has the year and the y axis is the math scores (`value` in dataframe), and there are separate lines/colors for male versus female students (`varValueLabel` in dataframe)\n",
    "\n",
    "Start the limits of the y axis minimum at 272 and add informative labels. Be sure your x-axis is ticked on odd years, because NAEP scores skip even years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reproduce the queries from 1.1 and 1.2 using a user-defined function (4 points)\n",
    "\n",
    "Create a function, `construct_naep_query` that takes in two arguments:\n",
    "\n",
    "- year: this should be a list with all years (so if one year, single element list; if multiple years, list with those years)\n",
    "- place: this should be a string with the name of the state or jurisdiction to pull \n",
    "    \n",
    "Have the function return the query and make sure it's identical to the queries you wrote for 1.1 and 1.2 (can use assert or other checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to execute function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Write and execute user-defined function that takes in a query and returns a pandas dataframe with the content of the response (4 points)\n",
    "\n",
    "- Write a user-defined function (`process_naep_query`) that takes in the CA-specific NAEP query as a string, calls the API, and transforms the response into a pandas dataframe. Have the function return that pandas dataframe\n",
    "\n",
    "- Make sure the function is flexible enough to handle queries that return an error; for queries that return an error, have the function return the string \"Data not found; check your query\" (see [API part 1 solutions code](https://github.com/herbertfreeze/QSS_public/blob/main/activities/solutions/06_apis_solutions.ipynb) for an example of `try:`/`except:`)\n",
    "\n",
    "- Execute the function on the query that pulls 2013-2019 data (either from handwriting the query or the result in 1.4)\n",
    "\n",
    "- Print the resulting dataframe\n",
    "\n",
    "- Then execute the function on a query that pulls a state that doesn't exist (call this state ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore data using SQL queries (18 points)\n",
    "\n",
    "In the previous example, you worked with the data in a flat file and manipulated it using pandas. Here, we're going to practice running queries to do some calculations using SQL --- in the case of our data, this is a bit overkill since the data are small but it is practice for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load database credentials and establish a connection (1 point)\n",
    "\n",
    "Load a credentials file that contains the credentials you'll need for this and the next problem:\n",
    "\n",
    "- The credentials for our class database\n",
    "- The credentials for the Census API (see instructions above)\n",
    "\n",
    "Note: to establish the SQL connection, you need to be on `eduroam` (near campus) or the Dartmouth's GlobalProtect `VPN`  ([installation instructions here](https://services.dartmouth.edu/TDClient/1806/Portal/KB/ArticleDet?ID=72395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = load_creds(\"PATH TO YOUR CREDS FILE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run a query to select all columns and the first 5 rows of the math_gencompare database to explore structure (2 points)\n",
    "\n",
    "Read the results in as a pandas dataframe and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Find the (1) number of rows in the database, (2) number of distinct states,  (3) number of distinct years (3 points)\n",
    "\n",
    "Interpret the results - how do you think the data is structured in terms of states and years (eg long format where each state repeated; wide format)?\n",
    "\n",
    "**Hint**: rather than using count `(*)` for the latter two, think about the `distinct` command in combination with `count`: https://www.w3resource.com/mysql/aggregate-functions-and-grouping/aggregate-functions-and-grouping-count-with-distinct.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Construct a new variable, `is_male_higher` that takes the value of 1 if the math scores of males exceed that of females in that state and year (each row) (2 points)\n",
    "\n",
    "Read in the results, print the head, and find the mean across all rows (the percentage of state-years where male students have higher scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 group by year and find the percentage of states where male scores are higher than females (4 points)\n",
    "\n",
    "**A.** Write a query that (1) groups by year and (2) finds the percentage of states that have higher scores for males than females in this year \n",
    "\n",
    "**B.** Print the resulting dataframe and interpret the results \n",
    "\n",
    "**Hint:** To compare male and female scores, consider logical operators (e.g., `<`, `>`, `=`) and simple aggregation (e.g., `avg()` to get mean) or using a subquery to construct the indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 group by state and find the percentage of years where male scores higher than females\n",
    "\n",
    "**A.** Write a query that (1) groups by state and (2) finds the percentage of years that have higher scores for males than females in that state\n",
    "\n",
    "**B.** Plot the results ordering the states from males higher all 4 years to males higher none of the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Use a subquery to create an indicator and group by that indicator (6 points)\n",
    "\n",
    "The following states were the first 6 to expand the right to vote to women before the uniform federal expansion in 1920\n",
    "\n",
    "- Wyoming 1890\n",
    "- Colorado 1893\n",
    "- Utah 1896\n",
    "- Idaho 1896\n",
    "- Washington 1910\n",
    "- California 1911\n",
    "\n",
    "**A.** Create an indicator `is_early_voter` for whether a state is in that list or not; do so without typing the state names inside the string and instead collapsing the list of states we provide and using something like `format`. Hint on how to combine the state names while preserving the quotes around each: https://stackoverflow.com/questions/12007686/join-a-list-of-strings-in-python-and-wrap-each-string-in-quotation-marks \n",
    "\n",
    "**B.** Then, group by the `is_early_voter` indicator and `year` and find the percencentage of states in each group where males had higher scores than females \n",
    "\n",
    "**C.** Print the resulting dataframe and interpret. Does early expansion of voting seem to be correlated with girls scoring better on the math tests a century later?\n",
    "\n",
    "**Hint:** in order to group by the indicator in step b, you may need to use a subquery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of states we provide\n",
    "list_suffrage = [\"Wyoming\", \"Colorado\", \"Utah\", \"Idaho\", \"Washington\", \n",
    "                \"California\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore variation in math score disparities and trends (18 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Read in the `acs_wmath.pkl` file (csv is backup) (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create a visualization where one axis is the state; the other axis is the male 2013 math scores - the female 2013 math scores (gender disparity) (2 points)\n",
    "\n",
    "\n",
    "You have free rein over additional details but make sure it is informative over what direction of disparity positive versus negative values mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Examine gender disparity in relation to household income (6 points)\n",
    "\n",
    "**A.** Construct an indicator variable for the state having better performance of males in 2013 than females\n",
    "\n",
    "**B.** First plot a scatterplot (or seaborn regplot) of estimated median household income from the acs data (we provide varname below) vs `math_male_2013`. Then do a second smoothed scatterplot for median household income vs `math_female_2013`.\n",
    "\n",
    "**C.** \n",
    "Then use the `np.corrcoef` command (three separate times) to examine the bivariate correlation of\n",
    "- male performance\n",
    "- female performance\n",
    "- the indicator variable from **A** \n",
    "\n",
    "with median household income (`acspredict_median_household_income_in_the_past_12_months__in_2018_inflation-adjusted_dollars_estimatemedian household income in the past 12 months in 2018 inflationadjusted dollars`)\n",
    "\n",
    "Documentation: https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "\n",
    "**D.** Interpret the correlations - in states with higher median household income (MHI), do \n",
    "   - boys tend to perform better than boys in states with lower MHI?\n",
    "   - girls tend to perform better than girls in states with lower MHI?\n",
    "   - boys tend to outperform girls more than they do in states with lower MHI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Predicting disparities (10 points)\n",
    "\n",
    "**A.** Read in the raw `acs_wmath` data again (this loses the variables you created above)\n",
    "\n",
    "**B.** Construct a binary indicator variable for male score > female score  for each year - for full credit, do so without repeating the difference code for each of the four years: name these according to following convention: `outcome_male_higher_female_year` where year is 2013, 2015, 2017, or 2019 (e.g., 2013: `outcome_male_higher_female_2013`). After this, remove the raw math scores as columns in the data (so filter out any column with the word math)\n",
    "\n",
    "**C.** Melt the data (`acs_wmath`) to long where instead of wide years, years are repeated within state; the ACS vars will also be repeated since we only pulled one year. In other words, reshape the data from \"wide format\", where each state is a row and we have separate columns for each year, to \"long format\", where states are repeated four times: once for each year in the data (2013, 2015, 2017, 2019). With 50 states, your final shape should be (200,84).\n",
    "- See: https://pandas.pydata.org/docs/reference/api/pandas.melt.html\n",
    "\n",
    "**D.** Split into train-test split at state level (so all years in same state -> either all in train or all test). Randomize 35 states to train; 15 states in test. \n",
    "\n",
    "**E.** Normalize the features to mean 0, variance 1 and estimate a decision tree with a max depth of 5. Your covariates should have the term 'acspredict' in it.\n",
    "\n",
    "- **Hint:** The ML literature recommends using the training set scaler to transform the test set, rather than using a unique scaler to initialize each one. The reasons are discussed here: https://stats.stackexchange.com/questions/495357/why-do-we-normalize-test-data-on-the-parameters-of-the-training-data\n",
    "\n",
    "**F.** Interpret the feature importances\n",
    "\n",
    "**G.** Evaluate the precision and recall of that model in the test set states without using the `score`, `precision`, or `recall` functions in sklearn. Briefly interpret: compared to our class example (a high-dimensional feature matrix of yelp reviews with ~15000 observations), why do you think our models perform worse for this set of data/predictors?\n",
    "\n",
    "**Additional resources:** \n",
    "\n",
    "- Feature normalization: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "- Definition of precision and recall: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. your code here to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. your code here to construct binary indicators for male higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. your code here to melt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. your code here for train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. your code here to normalize features and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. your code here to interpret feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G. your code here to evaluate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
